
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@INPROCEEDINGS{art1,
  author={Shah, Samkit and Bandariya, Jayraj and Jain, Garima and Ghevariya, Mayur and Dastoor, Sarosh},
  booktitle={2019 3rd International Conference on Trends in Electronics and Informatics (ICOEI)}, 
  title={CNN based Auto-Assistance System as a Boon for Directing Visually Impaired Person}, 
  year={2019},
  volume={},
  number={},
  pages={235-240},
  doi={10.1109/ICOEI.2019.8862699}}

@INPROCEEDINGS{art2,
  author={Bastomi, Rais and Ariatama, Firza Putra and Putri, Lucke Yuansyah Arif Tryas and Saputra, Septian Wahyu and Maulana, Mohammad Rizki and Syaiâ€™in, Mat and Munadhif, Ii and Khumaidi, Agus and Rahmat, Mohammad Basuki and Setiyoko, Annas Singgih and Herijono, Budi and Zuliari, E.A. and Mardlijah},
  booktitle={2019 International Symposium on Electronics and Smart Devices (ISESD)}, 
  title={Object Detection and Distance Estimation Tool for Blind People Using Convolutional Methods with Stereovision}, 
  year={2019},
  volume={},
  number={},
  pages={1-5},
  doi={10.1109/ISESD.2019.8909515}}


@INPROCEEDINGS{art3,
  author={Atiba, Samuelson Tijesunimi and Funmilola Moses, Sarah and Lakoju, Mike and Semire, Folasade A. and Aldmour, Rakan},
  booktitle={2020 13th International Conference on Developments in eSystems Engineering (DeSE)}, 
  title={Machine Vision Intelligent Travel Aid for the Visually Impaired (ITAVI) in Developing Countries}, 
  year={2020},
  volume={},
  number={},
  pages={317-322},
  doi={10.1109/DeSE51703.2020.9450744}}

@Article{art4,
AUTHOR = {Joshi, Rakesh Chandra and Yadav, Saumya and Dutta, Malay Kishore and Travieso-Gonzalez, Carlos M.},
TITLE = {Efficient Multi-Object Detection and Smart Navigation Using Artificial Intelligence for Visually Impaired People},
JOURNAL = {Entropy},
VOLUME = {22},
YEAR = {2020},
NUMBER = {9},
ARTICLE-NUMBER = {941},
URL = {https://www.mdpi.com/1099-4300/22/9/941},
PubMedID = {33286711},
ISSN = {1099-4300},
ABSTRACT = {Visually impaired people face numerous difficulties in their daily life, and technological interventions may assist them to meet these challenges. This paper proposes an artificial intelligence-based fully automatic assistive technology to recognize different objects, and auditory inputs are provided to the user in real time, which gives better understanding to the visually impaired person about their surroundings. A deep-learning model is trained with multiple images of objects that are highly relevant to the visually impaired person. Training images are augmented and manually annotated to bring more robustness to the trained model. In addition to computer vision-based techniques for object recognition, a distance-measuring sensor is integrated to make the device more comprehensive by recognizing obstacles while navigating from one place to another. The auditory information that is conveyed to the user after scene segmentation and obstacle identification is optimized to obtain more information in less time for faster processing of video frames. The average accuracy of this proposed method is 95.19% and 99.69% for object detection and recognition, respectively. The time complexity is low, allowing a user to perceive the surrounding scene in real time.},
DOI = {10.3390/e22090941}
}

@Article{art5,
AUTHOR = {R. Meenakshi, R. Ponnusamy, Saleh Alghamdi, Osama Ibrahim Khalaf, Youseef Alotaibi},
TITLE = {Development of Mobile App to Support the Mobility of Visually Impaired People},
JOURNAL = {Computers, Materials \& Continua},
VOLUME = {73},
YEAR = {2022},
NUMBER = {2},
PAGES = {3473--3495},
URL = {http://www.techscience.com/cmc/v73n2/48359},
ISSN = {1546-2226},
ABSTRACT = {In 2017, it was estimated that the number of persons of all ages visually affected would be two hundred and eighty-five million, of which thirty-nine million are blind. There are several innovative technical solutions available to facilitate the movement of these people. The next big challenge for technical people is to give cost-effective solutions. One of the challenges for people with visual impairments is navigating safely, recognizing obstacles, and moving freely between locations in unfamiliar environments. A new mobile application solution is developed, and the application can be installed in android mobile. The application will visualize the environment with portable cameras and persons with visual impairment directly to the environment. The designed system mainly uses the YOLO3 program to identify and locate the distance between the objects and the camera. Furthermore, it determines the direction of the object. Finally, the system will give the voice command to teach/inform the visually impaired people to navigate the environment. It is a novel work at the global level. The proposed approach is cost-effective and affordable to all strata of society.},
DOI = {10.32604/cmc.2022.028540}
}